/* This configuration file is the fastest way to get started with the TPE
optimization algorithm. It contains only mandatory options with commonly used
values. All other options can be considered as advanced mode and require
deep knowledge of the quantization process. Find overall description of all possible
parameters in tpe_spec.json */

{
    /* Model parameters */

    "model": {
        "model_name": "model_name", // Model name
        "model": "<MODEL_PATH>", // Path to a model (.xml format)
        "weights": "<PATH_TO_WEIGHTS>" // Path to weights (.bin format)
    },

    /* Parameters of the engine used for model inference. */

    "engine": {
        "config": "<CONFIG_PATH>" // Path to Accuracy Checker config
    },

    /* Optimizer used to find "optimal" hyperparameters */

    "optimizer": {
        "name": "Tpe", // Global optimizer name
        "params": {
            "max_trials": 200, // Maximum number of trails
            "trials_load_method": "cold_start", // Start from scratch or reuse previous results, supported options [cold_start, warm_start, fine_tune, eval]
            "accuracy_loss": 0.1, // Accuracy threshold (%)
            "latency_reduce": 1.5, // Target latency improvement versus original model
            "accuracy_weight": 1.0, // Accuracy weight in loss function
            "latency_weight": 1.0, // Latency weight in loss function
            "benchmark": {
                // Latency measurement benchmark configuration (https://docs.openvinotoolkit.org/latest/_inference_engine_samples_benchmark_app_README.html)
                "performance_count": false,
                "batch_size": 0,
                "nthreads": 4,
                "nstreams": 0,
                "nireq": 0,
                "api_type": "sync",
                "niter": 4,
                "duration_seconds": 30,
                "benchmark_app_dir": "<path to benchmark_app>" // Path to benchmark_app If not specified, Python base benchmark will be used. Use benchmark_app to reduce jitter in results.
            }
        }
    },

    /* Optimization hyperparameters */

    "compression": {
        "target_device": "ANY", // Target device, the specificity of which will be taken
                                // into account during optimization
        "algorithms": [
            {
                "name": "ActivationChannelAlignment",
                "params": {
                    "stat_subset_size": 300 // Size of subset to calculate activations statistics that can be used
                                            // for quantization parameters calculation.
                }
            },
            {
                "name": "TunableQuantization",
                "params": {
                    /* Preset is a collection of optimization algorithm parameters that will specify to the algorithm
                    to improve which metric the algorithm needs to concentrate. Each optimization algorithm supports
                    [performance, mixed, accuracy] presets which control the quantization mode
                    (symmetric, mixed(weights symmetric and activations asymmetric), and fully asymmetric respectively)*/
                    "preset": "performance",
                    "stat_subset_size": 300,   // Size of subset to calculate activations statistics that can be used
                                               // for quantization parameters calculation.
                    "tuning_scope": ["layer"] // List of quantization parameters that will be tuned,
                                              // available options: [bits, mode, granularity, layer, range_estimator]
                }
            },
            {
                "name": "FastBiasCorrection",
                "params": {
                    "stat_subset_size": 300 // Size of subset to calculate activations statistics that can be used
                                            // for quantization parameters calculation.
                }
            }
        ]
    }
}
